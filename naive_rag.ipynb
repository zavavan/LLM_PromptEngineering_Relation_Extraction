{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf9a757",
   "metadata": {},
   "source": [
    "![image](../images/kdd24-logo-small.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15f08dc",
   "metadata": {},
   "source": [
    "# Hands-on Tutorial\n",
    "## Domain-Driven LLM Development: Insights into RAG and Fine-Tuning Practices\n",
    "### Lab 1.1: Naive RAG\n",
    "#### Summary: \n",
    "Objective:\n",
    "This notebook demonstrates the implementation of a Naive Retrieval-Augmented Generation (RAG) pipeline using the following components:\n",
    "\n",
    "- Embedding Model: `amazon.titan-embed-text-v2:0`\n",
    "\n",
    "- Vector Database: `Epsilla's vector database`\n",
    "\n",
    "- Large Language Model (LLM): `meta.llama3-8b-instruct-v1:0`\n",
    "\n",
    "The data we use is BONTONSTORESINC_04_20_2018-EX-99.3-AGENCY AGREEMENT and ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALLIANCE AGREEMENT from the Contract Understanding Atticus Dataset (https://github.com/TheAtticusProject/cuad)\n",
    "\n",
    "We also demostrate evaluating RAG correctness with 3 metrics:\n",
    "\n",
    "- cosine similarity\n",
    "- token_overlap_recall\n",
    "- rouge_l_recall\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc995ef",
   "metadata": {},
   "source": [
    "#### Load the PDF file as text string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8920bfb1-54a7-4c8c-9c45-591759e73b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3197.85s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.24.9)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from PyMuPDF) (1.24.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6be99b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb8173e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text using PyMuPDF\n",
    "def extract_text_from_pdf_mupdf(pdf_path):\n",
    "    text = \"\"\n",
    "    document = fitz.open(pdf_path)\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae8ea34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EXHIBIT 99.3\\nCase 18-10248-\\nMFW\\nDoc 632-1\\nFiled 04/18/18\\nPage 2 of 60\\nAGENCY AGREEMENT\\nThis Agency Agreement (“Agreement”) is made as of April 18, 2018, by and between The Bon-Ton Stores, Inc. and its associated chapter 11 debtors in\\npossession (collectively, “Merchant”),1 on the one hand, and (a) a contractual joint venture comprised of GA Retail, Inc. (“GA”) and Tiger Capital Group, LLC\\n(“Tiger” and collectively with GA, the “Agent”) and (b) Wilmington Savings Fund Society, FSB, as the indenture agent and collateral trustee for the 8.00%\\nsecond-lien senior secured notes due 2021 (the “Second-Lien Notes”) issued by BTDS, on the other hand (in such capacities, the “Notes Trustee” and\\ncollectively with Agent, “Purchaser”). Purchaser and Merchant are collectively the “Parties.”\\nSection 1. Recitals\\nWHEREAS, on February 4, 2018, the entities comprising Merchant commenced ten voluntary chapter 11 bankruptcy cases (the “Bankruptcy Cases”) in\\nthe United States Bankruptcy Court for the District of Delaware (the “Bankruptcy Court”).\\nWHEREAS, pursuant to an order of the Bankruptcy Court entered on February 6, 2018 [D.I. 105], the Bankruptcy Cases are being jointly administered\\nunder the caption In re The Bon-Ton Stores, Inc., et al., Lead Case No. 18-10248-MFW (Bankr. D. Del.).\\nWHEREAS, on March 12, 2018, the Bankruptcy Court entered an order (the “Bidding Procedures Order”) [D.I. 348] that, among other relief, approved\\nbidding procedures (the “Bidding Procedures”) for and scheduled a hearing (the “Sale Approval Hearing”) on the approval of the sale of all or substantially of\\nMerchant’s assets.\\nWHEREAS, on March 12, 2018, the Bankruptcy Court entered an order (the “Final DIP Order”) [D.I. 352] authorizing Merchant to obtain postpetition\\nsecured debtor-in-possession financing on a final basis.\\nWHEREAS, an ad hoc group of holders of $251,325,000 in principal amount of the Second-Lien Notes (the “Second Lien Noteholders”) has issued a\\ndirection to the Notes Trustee to credit bid'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the text from the PDF using PyMuPDF\n",
    "pdf_text_mupdf = extract_text_from_pdf_mupdf(\"../lab-data/BONTONSTORESINC_04_20_2018-EX-99.3-AGENCY AGREEMENT.PDF\")\n",
    "pdf_text_mupdf[:2000]  # Displaying the first 2000 characters to get an overview of the content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739fef89",
   "metadata": {},
   "source": [
    "#### Chunk the document with uniform length strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01f6bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size, overlap):\n",
    "    \"\"\"\n",
    "    Chunk text into smaller segments with a specified chunk size and overlap.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text to be chunked.\n",
    "    - chunk_size (int): The size of each chunk.\n",
    "    - overlap (int): The number of characters that overlap between chunks.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list of text chunks.\n",
    "    \"\"\"\n",
    "    if chunk_size <= overlap:\n",
    "        raise ValueError(\"Chunk size must be greater than overlap\")\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    end = chunk_size\n",
    "\n",
    "    while start < len(text):\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start += chunk_size - overlap\n",
    "        end = start + chunk_size\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baa6cba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EXHIBIT 99.3\\nCase 18-10248-\\nMFW\\nDoc 632-1\\nFiled 04/18/18\\nPage 2 of 60\\nAGENCY AGREEMENT\\nThis Agency Agreement (“Agreement”) is made as of April 18, 2018, by and between The Bon-Ton Stores, Inc. and its associated chapter 11 debtors in\\npossession (collectively, “Merchant”),1 on the one hand, and (a) a contractual joint venture comprised of GA Retail, Inc. (“GA”) and Tiger Capital Group, LLC\\n(“Tiger” and collectively with GA, the “Agent”) and (b) Wilmington Savings Fund Society, FSB, as the indenture agent and collateral trustee for the 8.00%\\nsecond-lien senior secured notes due 2021 (the “Second-Lien Notes”) issued by BTDS, on the other hand (in such capacities, the “Notes Trustee” and\\ncollectively with Agent, “Purchaser”). Purchaser and Merchant are collectively the “Parties.”\\nSection 1. Recitals\\nWHEREAS, on February 4, 2018, the entities comprising Merchant commenced ten voluntary chapter 11 bankruptcy cases (the “Bankruptcy Cases”) in\\nthe United States Bankruptcy Court for the District of Delaware (the “Bank',\n",
       " 'ely the “Parties.”\\nSection 1. Recitals\\nWHEREAS, on February 4, 2018, the entities comprising Merchant commenced ten voluntary chapter 11 bankruptcy cases (the “Bankruptcy Cases”) in\\nthe United States Bankruptcy Court for the District of Delaware (the “Bankruptcy Court”).\\nWHEREAS, pursuant to an order of the Bankruptcy Court entered on February 6, 2018 [D.I. 105], the Bankruptcy Cases are being jointly administered\\nunder the caption In re The Bon-Ton Stores, Inc., et al., Lead Case No. 18-10248-MFW (Bankr. D. Del.).\\nWHEREAS, on March 12, 2018, the Bankruptcy Court entered an order (the “Bidding Procedures Order”) [D.I. 348] that, among other relief, approved\\nbidding procedures (the “Bidding Procedures”) for and scheduled a hearing (the “Sale Approval Hearing”) on the approval of the sale of all or substantially of\\nMerchant’s assets.\\nWHEREAS, on March 12, 2018, the Bankruptcy Court entered an order (the “Final DIP Order”) [D.I. 352] authorizing Merchant to obtain postpetition\\nsecured debtor-in-possession financ']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = chunk_text(pdf_text_mupdf, 1024, 256)\n",
    "print(len(chunks))\n",
    "chunks[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00079592",
   "metadata": {},
   "source": [
    "#### Setup the embedding service\n",
    "\n",
    "Utilize the amazon.titan-embed-text-v2:0 model to convert the documents into dense vector embeddings. Each document will be transformed into a high-dimensional vector representation that captures its semantic content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bcf61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62329911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Bedrock client\n",
    "client = boto3.client('bedrock-runtime', region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844f15dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embedding\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Print the embedding\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28mprint\u001b[39m(embed_text(\u001b[43mchunks\u001b[49m[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chunks' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to embed text\n",
    "def embed_text(input_text):\n",
    "    # Create the request payload\n",
    "    payload = {\n",
    "        \"inputText\": input_text,\n",
    "        \"dimensions\": 512,  # Specify the desired dimension size\n",
    "        \"normalize\": True  # Whether to normalize the output embeddings\n",
    "    }\n",
    "\n",
    "    # Invoke the model\n",
    "    response = client.invoke_model(\n",
    "        body=json.dumps(payload),\n",
    "        modelId='amazon.titan-embed-text-v2:0',  # Specify the Titan embedding model\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    # Get the embedding result\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    embedding = response_body.get('embedding')\n",
    "    return embedding\n",
    "\n",
    "# Print the embedding\n",
    "print(embed_text(chunks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93366c61",
   "metadata": {},
   "source": [
    "#### Setup vector database, and build knowledge base from the PDF document\n",
    "\n",
    "Store the generated embeddings in Epsilla's vector database. The database will be configured to allow efficient similarity search, which is critical for the retrieval step in RAG.\n",
    "\n",
    "Ensure that each embedding is stored with a reference to its original document so that it can be retrieved later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6cafe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyepsilla\n",
      "  Downloading pyepsilla-0.3.7-py3-none-any.whl.metadata (474 bytes)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pyepsilla) (2.32.3)\n",
      "Collecting sentry-sdk (from pyepsilla)\n",
      "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting posthog (from pyepsilla)\n",
      "  Downloading posthog-3.5.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pydantic (from pyepsilla)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from posthog->pyepsilla) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog->pyepsilla)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog->pyepsilla)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from posthog->pyepsilla) (2.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->pyepsilla) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->pyepsilla) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->pyepsilla) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->pyepsilla) (2024.7.4)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic->pyepsilla)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic->pyepsilla)\n",
      "  Downloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic->pyepsilla) (4.12.2)\n",
      "Downloading pyepsilla-0.3.7-py3-none-any.whl (25 kB)\n",
      "Downloading posthog-3.5.2-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Installing collected packages: monotonic, sentry-sdk, pydantic-core, backoff, annotated-types, pydantic, posthog, pyepsilla\n",
      "Successfully installed annotated-types-0.7.0 backoff-2.2.1 monotonic-1.6 posthog-3.5.2 pydantic-2.8.2 pydantic-core-2.20.1 pyepsilla-0.3.7 sentry-sdk-2.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyepsilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4f7cdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "latest: Pulling from epsilla/vectordb\n",
      "\n",
      "\u001b[1B29bcf202: Pulling fs layer \n",
      "\u001b[1B555358b1: Pulling fs layer \n",
      "\u001b[1Bb700ef54: Pulling fs layer \n",
      "\u001b[1Ba17be611: Pulling fs layer \n",
      "\u001b[1B934d8b21: Pulling fs layer \n",
      "\u001b[1B5cb974f3: Pulling fs layer \n",
      "\u001b[1B6f850f31: Pulling fs layer \n",
      "\u001b[1B42c631d3: Pulling fs layer \n",
      "\u001b[1B09595de6: Pull complete 421MB/421MBkBBA\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[1A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[6A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[8A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2KExtracting  304.7kB/304.7kB\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:fee11976ed6428a5b4c62e95c9ddebd5083abc17e28e8d34fde625f7de35ebfb\n",
      "Status: Downloaded newer image for epsilla/vectordb:latest\n",
      "docker.io/epsilla/vectordb:latest\n",
      "0d6b12fa7c4ba3b23d370e6274bf900b8e869e6e314dc5d88f096023e424781a\n",
      "Check Vector DB:\n",
      "curl: (52) Empty reply from server\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sh ../setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c35cb244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Connected to localhost:8888 successfully.\n"
     ]
    }
   ],
   "source": [
    "from pyepsilla import vectordb\n",
    "## connect to vectordb\n",
    "db = vectordb.Client(\n",
    "  host='localhost',\n",
    "  port='8888'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "310f9342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, {'statusCode': 200, 'message': 'Load/Create kdd_lab1_rag successfully.'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.unload_db(\"kdd_lab1_rag\")\n",
    "db.load_db(db_name=\"kdd_lab1_rag\", db_path=\"/tmp/kdd_lab1_rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e7eb67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, {'statusCode': 200, 'message': 'Create NaiveRAG successfully.'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.use_db(db_name=\"kdd_lab1_rag\")\n",
    "db.create_table(\n",
    "  table_name=\"NaiveRAG\",\n",
    "  table_fields=[\n",
    "    {\"name\": \"ID\", \"dataType\": \"INT\", \"primaryKey\": True},\n",
    "    {\"name\": \"Doc\", \"dataType\": \"STRING\"},\n",
    "    {\"name\": \"Embedding\", \"dataType\": \"VECTOR_FLOAT\", \"dimensions\": 512}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbc7b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "records = [\n",
    "    {\n",
    "        \"ID\": index,\n",
    "        \"Doc\": text,\n",
    "        \"Embedding\": embed_text(text)\n",
    "    }\n",
    "    for index, text in enumerate(chunks)\n",
    "]\n",
    "records[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a90d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.insert(\"NaiveRAG\", records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6188ae",
   "metadata": {},
   "source": [
    "#### Setup interence service\n",
    "\n",
    "Use `meta.llama3-8b-instruct-v1:0` as LLM for completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8453db0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AccessDeniedException",
     "evalue": "An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAccessDeniedException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 41\u001b[0m\n\u001b[1;32m     30\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124m<s>[INST] <<SYS>>\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124mYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;132;01m{\u001b[39;00minput_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m[/INST]\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     10\u001b[0m client \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39mclient(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbedrock-runtime\u001b[39m\u001b[38;5;124m'\u001b[39m, region_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mus-west-2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Invoke the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodelId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmeta.llama3-8b-instruct-v1:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontentType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m byte_response \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     21\u001b[0m json_string \u001b[38;5;241m=\u001b[39m byte_response\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mAccessDeniedException\u001b[0m: An error occurred (AccessDeniedException) when calling the InvokeModel operation: You don't have access to the model with the specified model ID."
     ]
    }
   ],
   "source": [
    "def generate(prompt):\n",
    "    # Create the request payload\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"temperature\": 0,  # Adjust the randomness of the output\n",
    "        \"max_gen_len\": 128\n",
    "    }\n",
    "\n",
    "    # Initialize the Bedrock runtime client\n",
    "    client = boto3.client('bedrock-runtime', region_name='us-west-2')\n",
    "\n",
    "    # Invoke the model\n",
    "    response = client.invoke_model(\n",
    "        modelId='meta.llama3-8b-instruct-v1:0',\n",
    "        contentType='application/json',\n",
    "        accept='application/json',\n",
    "        body=json.dumps(payload)\n",
    "    )\n",
    "    \n",
    "    byte_response = response['body'].read()\n",
    "    json_string = byte_response.decode('utf-8')\n",
    "\n",
    "    # Get the chat response\n",
    "    response_body = json.loads(json_string)\n",
    "    chat_response = response_body.get('generation')\n",
    "\n",
    "    return chat_response\n",
    "\n",
    "# Example usage\n",
    "input_text = \"How are you?\"\n",
    "prompt = f\"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "\n",
    "{input_text}[/INST]\n",
    "\"\"\"\n",
    "\n",
    "print(generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731ebd4",
   "metadata": {},
   "source": [
    "#### Setup the RAG pipeline\n",
    "\n",
    "When a query is received, embed the query using the same amazon.titan-embed-text-v2:0 model to generate a query vector.\n",
    "\n",
    "Perform a similarity search in Epsilla's vector database to retrieve the most relevant documents based on the cosine similarity between the query vector and the stored document embeddings.\n",
    "\n",
    "Pass the retrieved documents (or their summaries) along with the original query to meta.llama3-8b-instruct-v1:0.\n",
    "\n",
    "The LLM will generate a response that is contextually informed by the retrieved documents, effectively augmenting the generation with relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90733e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_retriever(table_name, question, top_k):\n",
    "    code, resp = db.query(\n",
    "        table_name=table_name,\n",
    "        query_field=\"Embedding\",\n",
    "        query_vector=embed_text(question),\n",
    "        limit=top_k\n",
    "    )\n",
    "    return resp[\"result\"]\n",
    "basic_retriever(\"NaiveRAG\", \"What's the agreement date?\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def naive_rag(table_name, question):\n",
    "    docs = basic_retriever(table_name, question, 5)\n",
    "    docs_str = \"------------------------\\n\"\n",
    "    for doc in docs:\n",
    "        docs_str += doc[\"Doc\"] + \"\\n------------------------\\n\"\n",
    "    prompt = f\"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "\n",
    "Your answer should be grounded by the information provided in the documents below.\n",
    "Don't make up answers.\n",
    "Don't explain your thought process.\n",
    "Directly answer the question in concise way.\n",
    "\n",
    "<documents>\n",
    "{docs_str}\n",
    "</documents>\n",
    "<</SYS>>\n",
    "\n",
    "{question}[/INST]\n",
    "\"\"\"\n",
    "    cleaned_response = re.sub(r'</?[^>]+>', '', generate(prompt))\n",
    "    return prompt, cleaned_response\n",
    "\n",
    "data_augmented_prompt, answer = naive_rag(\"NaiveRAG\", \"What's the agreement date?\")\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67877d8",
   "metadata": {},
   "source": [
    "#### Evaluation on question answer accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e74260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the text from the PDF using PyMuPDF\n",
    "pdf_text_mupdf = extract_text_from_pdf_mupdf(\"../lab-data/ENERGOUSCORP_03_16_2017-EX-10.24-STRATEGIC ALLIANCE AGREEMENT.PDF\").replace('\\xa0', ' ')\n",
    "pdf_text_mupdf  # Displaying the first 2000 characters to get an overview of the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_text(pdf_text_mupdf, 1024, 256)\n",
    "print(len(chunks))\n",
    "chunks[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c3de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.create_table(\n",
    "  table_name=\"NaiveRAG_Evaluation\",\n",
    "  table_fields=[\n",
    "    {\"name\": \"ID\", \"dataType\": \"INT\", \"primaryKey\": True},\n",
    "    {\"name\": \"Doc\", \"dataType\": \"STRING\"},\n",
    "    {\"name\": \"Embedding\", \"dataType\": \"VECTOR_FLOAT\", \"dimensions\": 512}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [\n",
    "    {\n",
    "        \"ID\": index,\n",
    "        \"Doc\": text,\n",
    "        \"Embedding\": embed_text(text)\n",
    "    }\n",
    "    for index, text in enumerate(chunks)\n",
    "]\n",
    "records[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f87917",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.insert(\"NaiveRAG_Evaluation\", records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaab958",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_retriever(\"NaiveRAG_Evaluation\", \"What's the agreement date?\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53cde92",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_rag(\"NaiveRAG_Evaluation\", \"According to the contract, how is the renewal term handled after the initial term expires, including details on automatic extensions or extensions requiring prior notice?\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89160ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '../lab-data/ENERGOUSCORP_qa.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the CSV has 'Question' and 'Answer' columns\n",
    "questions = df['question'].tolist()\n",
    "answers = df['answer'].tolist()\n",
    "\n",
    "questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f7f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented_prompts = []\n",
    "generated_answers = []\n",
    "for question in questions:\n",
    "    data_augmented_prompt, generated_answer = naive_rag(\"NaiveRAG_Evaluation\", question)\n",
    "    data_augmented_prompts.append(data_augmented_prompt)\n",
    "    generated_answers.append(generated_answer)\n",
    "\n",
    "generated_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1818bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install continuous-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31672f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c16de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from continuous_eval.metrics.generation.text import DeterministicAnswerCorrectness\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "evaluation_results = []\n",
    "for i in range(len(questions)):\n",
    "    ground_truth_embedding = embed_text(answers[i])\n",
    "    answer_embedding = embed_text(generated_answers[i])\n",
    "    cosine_similarity = util.cos_sim(ground_truth_embedding, answer_embedding)[0][0].item()\n",
    "    \n",
    "    datum = {\n",
    "        \"answer\": generated_answers[i],\n",
    "        \"ground_truth_answers\": [\n",
    "            answers[i]\n",
    "        ]\n",
    "    }\n",
    "    metric = DeterministicAnswerCorrectness()\n",
    "    eval_result = metric(**datum)\n",
    "    evaluation_results.append({\n",
    "        \"question\": data_augmented_prompts[i],\n",
    "        \"ref_answer\": answers[i],\n",
    "        \"response\": generated_answers[i],\n",
    "        \"semantic_similarity\": cosine_similarity,\n",
    "        \"token_overlap_recall\": eval_result[\"token_overlap_recall\"],\n",
    "        \"rouge_l_recall\": eval_result[\"rouge_l_recall\"]\n",
    "    })\n",
    "\n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932206f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Specify the file name\n",
    "csv_file = '../lab-data/naive_rag_result.csv'\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=evaluation_results[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(evaluation_results)\n",
    "\n",
    "csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d79a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = '../lab-data/ENERGOUSCORP_qa_test.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the CSV has 'Question' and 'Answer' columns\n",
    "questions = df['question'].tolist()\n",
    "answers = df['answer'].tolist()\n",
    "\n",
    "questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented_prompts = []\n",
    "generated_answers = []\n",
    "for question in questions:\n",
    "    data_augmented_prompt, generated_answer = naive_rag(\"NaiveRAG_Evaluation\", question)\n",
    "    data_augmented_prompts.append(data_augmented_prompt)\n",
    "    generated_answers.append(generated_answer)\n",
    "\n",
    "generated_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db44c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = []\n",
    "for i in range(len(questions)):\n",
    "    ground_truth_embedding = embed_text(answers[i])\n",
    "    answer_embedding = embed_text(generated_answers[i])\n",
    "    cosine_similarity = util.cos_sim(ground_truth_embedding, answer_embedding)[0][0].item()\n",
    "    \n",
    "    datum = {\n",
    "        \"answer\": generated_answers[i],\n",
    "        \"ground_truth_answers\": [\n",
    "            answers[i]\n",
    "        ]\n",
    "    }\n",
    "    metric = DeterministicAnswerCorrectness()\n",
    "    eval_result = metric(**datum)\n",
    "    evaluation_results.append({\n",
    "        \"question\": data_augmented_prompts[i],\n",
    "        \"ref_answer\": answers[i],\n",
    "        \"response\": generated_answers[i],\n",
    "        \"semantic_similarity\": cosine_similarity,\n",
    "        \"token_overlap_recall\": eval_result[\"token_overlap_recall\"],\n",
    "        \"rouge_l_recall\": eval_result[\"rouge_l_recall\"]\n",
    "    })\n",
    "\n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50010f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name\n",
    "csv_file = '../lab-data/naive_rag_test_result.csv'\n",
    "\n",
    "# Write the data to a CSV file\n",
    "with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=evaluation_results[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(evaluation_results)\n",
    "\n",
    "csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31bc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0215e651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
